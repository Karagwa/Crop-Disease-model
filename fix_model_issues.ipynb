{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0eb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "551732ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® FIXING DATA LEAKAGE ISSUE\n",
      "============================================================\n",
      "PROBLEM IDENTIFIED:\n",
      "   ‚ùå Augmented images from same source appear in train/val/test\n",
      "   ‚ùå This causes data leakage and inflated performance\n",
      "   ‚ùå 90% test accuracy is likely invalid due to this issue\n",
      "\n",
      "üîß SOLUTION: CREATE PROPER SPLITS FROM ORIGINAL DATA\n",
      "============================================================\n",
      "üìÇ Collecting original files...\n",
      "‚úÖ Collected 35725 original images\n",
      "   Classes: 23\n",
      "\n",
      "üìä Creating proper stratified splits...\n",
      "‚úÖ Split sizes:\n",
      "   Train: 21435 images (60.0%)\n",
      "   Val: 7145 images (20.0%)\n",
      "   Test: 7145 images (20.0%)\n",
      "\n",
      "üìÅ Creating clean split directories...\n",
      "   Copying train files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21435/21435 [01:15<00:00, 282.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Copying val files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7145/7145 [00:24<00:00, 293.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Copying test files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7145/7145 [00:24<00:00, 296.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Applying augmentation ONLY to training set...\n",
      "   Target size per class in training: 1006\n",
      "   Augmenting Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot: 985 ‚Üí 1006 (+21)\n",
      "   Augmenting Pepper__bell___Bacterial_spot: 598 ‚Üí 1006 (+408)\n",
      "   Augmenting Pepper__bell___healthy: 887 ‚Üí 1006 (+119)\n",
      "   Augmenting Potato___Early_blight: 600 ‚Üí 1006 (+406)\n",
      "   Augmenting Potato___healthy: 91 ‚Üí 1006 (+915)\n",
      "   Augmenting Potato___Late_blight: 600 ‚Üí 1006 (+406)\n",
      "   Augmenting Tomato_Early_blight: 600 ‚Üí 1006 (+406)\n",
      "   Augmenting Tomato_healthy: 955 ‚Üí 1006 (+51)\n",
      "   Augmenting Tomato_Leaf_Mold: 571 ‚Üí 1006 (+435)\n",
      "   Augmenting Tomato__Target_Spot: 842 ‚Üí 1006 (+164)\n",
      "   Augmenting Tomato__Tomato_mosaic_virus: 224 ‚Üí 1006 (+782)\n",
      "\n",
      "‚úÖ CLEAN SPLITS CREATED - NO DATA LEAKAGE!\n",
      "   Path: Clean_Splits\n",
      "   Augmentation: Applied ONLY to training set\n",
      "   Val/Test: Original images only - NO augmentation\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FIX DATA LEAKAGE - CREATE PROPER SPLITS FROM ORIGINAL DATASET\n",
    "# =============================================================================\n",
    "\n",
    "def fix_data_leakage_and_create_proper_splits():\n",
    "    \"\"\"Fix data leakage by creating proper splits from original dataset\"\"\"\n",
    "    \n",
    "    print(\"üö® FIXING DATA LEAKAGE ISSUE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"PROBLEM IDENTIFIED:\")\n",
    "    print(\"   ‚ùå Augmented images from same source appear in train/val/test\")\n",
    "    print(\"   ‚ùå This causes data leakage and inflated performance\")\n",
    "    print(\"   ‚ùå 90% test accuracy is likely invalid due to this issue\")\n",
    "    \n",
    "    print(\"\\nüîß SOLUTION: CREATE PROPER SPLITS FROM ORIGINAL DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Work with original (non-augmented) dataset\n",
    "    original_data_path = 'Dataset/'  # Your original dataset\n",
    "    \n",
    "    # Collect all original files with their classes\n",
    "    all_original_files = []\n",
    "    class_to_id = {}\n",
    "    \n",
    "    print(\"üìÇ Collecting original files...\")\n",
    "    for class_id, class_name in enumerate(os.listdir(original_data_path)):\n",
    "        class_path = os.path.join(original_data_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_to_id[class_name] = class_id\n",
    "            \n",
    "            # Get only original images (not augmented)\n",
    "            image_files = [f for f in os.listdir(class_path) \n",
    "                          if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            \n",
    "            for img_file in image_files:\n",
    "                all_original_files.append({\n",
    "                    'file_name': img_file,\n",
    "                    'class_name': class_name,\n",
    "                    'class_id': class_id,\n",
    "                    'full_path': os.path.join(class_path, img_file)\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    original_df = pd.DataFrame(all_original_files)\n",
    "    \n",
    "    print(f\"‚úÖ Collected {len(original_df)} original images\")\n",
    "    print(f\"   Classes: {len(class_to_id)}\")\n",
    "    \n",
    "    # Step 2: Create proper stratified splits (NO DATA LEAKAGE)\n",
    "    print(\"\\nüìä Creating proper stratified splits...\")\n",
    "    \n",
    "    # Split at the IMAGE level (not augmented copies)\n",
    "    train_files, temp_files = train_test_split(\n",
    "        original_df,\n",
    "        test_size=0.4,  # 40% for val+test\n",
    "        stratify=original_df['class_id'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    val_files, test_files = train_test_split(\n",
    "        temp_files,\n",
    "        test_size=0.5,  # Split the 40% equally between val and test\n",
    "        stratify=temp_files['class_id'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Split sizes:\")\n",
    "    print(f\"   Train: {len(train_files)} images ({len(train_files)/len(original_df):.1%})\")\n",
    "    print(f\"   Val: {len(val_files)} images ({len(val_files)/len(original_df):.1%})\")\n",
    "    print(f\"   Test: {len(test_files)} images ({len(test_files)/len(original_df):.1%})\")\n",
    "    \n",
    "    # Step 3: Create physical directories with NO LEAKAGE\n",
    "    clean_split_path = 'Clean_Splits'\n",
    "    \n",
    "    # Remove old splits if they exist\n",
    "    if os.path.exists(clean_split_path):\n",
    "        shutil.rmtree(clean_split_path)\n",
    "    \n",
    "    # Create new directory structure\n",
    "    for split_name in ['train', 'val', 'test']:\n",
    "        for class_name in class_to_id.keys():\n",
    "            os.makedirs(os.path.join(clean_split_path, split_name, class_name), exist_ok=True)\n",
    "    \n",
    "    # Copy files to clean splits\n",
    "    splits_data = {\n",
    "        'train': train_files,\n",
    "        'val': val_files,\n",
    "        'test': test_files\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüìÅ Creating clean split directories...\")\n",
    "    for split_name, split_df in splits_data.items():\n",
    "        print(f\"   Copying {split_name} files...\")\n",
    "        for _, row in tqdm(split_df.iterrows(), total=len(split_df), desc=f\"Copying {split_name}\"):\n",
    "            src_path = row['full_path']\n",
    "            dst_path = os.path.join(clean_split_path, split_name, row['class_name'], row['file_name'])\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "    \n",
    "    # Step 4: Apply augmentation ONLY to training set\n",
    "    print(f\"\\nüîÑ Applying augmentation ONLY to training set...\")\n",
    "    \n",
    "    def augment_training_set_only(train_split_path):\n",
    "        \"\"\"Apply augmentation only to training set to prevent leakage\"\"\"\n",
    "        \n",
    "        train_datagen = ImageDataGenerator(\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.15,\n",
    "            height_shift_range=0.15,\n",
    "            horizontal_flip=True,\n",
    "            zoom_range=0.15,\n",
    "            shear_range=0.1,\n",
    "            brightness_range=[0.9, 1.1],\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        \n",
    "        # Count original training images per class\n",
    "        train_counts = {}\n",
    "        for class_name in os.listdir(train_split_path):\n",
    "            class_path = os.path.join(train_split_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                count = len([f for f in os.listdir(class_path) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                train_counts[class_name] = count\n",
    "        \n",
    "        # Calculate target size (median of current training sizes)\n",
    "        target_size = int(np.median(list(train_counts.values())))\n",
    "        print(f\"   Target size per class in training: {target_size}\")\n",
    "        \n",
    "        # Augment minority classes in training set only\n",
    "        for class_name, current_count in train_counts.items():\n",
    "            if current_count < target_size:\n",
    "                needed = target_size - current_count\n",
    "                class_path = os.path.join(train_split_path, class_name)\n",
    "                \n",
    "                print(f\"   Augmenting {class_name}: {current_count} ‚Üí {target_size} (+{needed})\")\n",
    "                \n",
    "                # Get original images in this class\n",
    "                original_images = [f for f in os.listdir(class_path) \n",
    "                                 if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "                \n",
    "                # Generate augmented images\n",
    "                generated = 0\n",
    "                max_attempts = needed * 3\n",
    "                attempts = 0\n",
    "                \n",
    "                while generated < needed and attempts < max_attempts:\n",
    "                    try:\n",
    "                        # Select random original image\n",
    "                        base_img = np.random.choice(original_images)\n",
    "                        img_path = os.path.join(class_path, base_img)\n",
    "                        \n",
    "                        # Load and augment\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is None:\n",
    "                            attempts += 1\n",
    "                            continue\n",
    "                        \n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                        img = img.reshape((1,) + img.shape)\n",
    "                        \n",
    "                        # Generate augmented image\n",
    "                        aug_iter = train_datagen.flow(img, batch_size=1)\n",
    "                        aug_img = next(aug_iter)[0].astype(np.uint8)\n",
    "                        \n",
    "                        # Save with clear augmentation prefix\n",
    "                        base_name = os.path.splitext(base_img)[0]\n",
    "                        ext = os.path.splitext(base_img)[1]\n",
    "                        aug_filename = f\"TRAIN_AUG_{generated:04d}_{base_name}{ext}\"\n",
    "                        aug_path = os.path.join(class_path, aug_filename)\n",
    "                        \n",
    "                        # Save\n",
    "                        aug_img_bgr = cv2.cvtColor(aug_img, cv2.COLOR_RGB2BGR)\n",
    "                        cv2.imwrite(aug_path, aug_img_bgr)\n",
    "                        \n",
    "                        generated += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        attempts += 1\n",
    "                        continue\n",
    "                    \n",
    "                    attempts += 1\n",
    "    \n",
    "    # Apply augmentation only to training set\n",
    "    train_split_path = os.path.join(clean_split_path, 'train')\n",
    "    augment_training_set_only(train_split_path)\n",
    "    \n",
    "    print(f\"\\n‚úÖ CLEAN SPLITS CREATED - NO DATA LEAKAGE!\")\n",
    "    print(f\"   Path: {clean_split_path}\")\n",
    "    print(f\"   Augmentation: Applied ONLY to training set\")\n",
    "    print(f\"   Val/Test: Original images only - NO augmentation\")\n",
    "    \n",
    "    return clean_split_path, splits_data, class_to_id\n",
    "\n",
    "# Execute the fix\n",
    "clean_split_path, clean_splits_data, clean_class_to_id = fix_data_leakage_and_create_proper_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "813a410c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç VALIDATING CLEAN SPLITS - NO DATA LEAKAGE CHECK\n",
      "============================================================\n",
      "üìä CLEAN SPLIT VALIDATION RESULTS:\n",
      "   Train files (unique): 21435\n",
      "   Val files (unique): 7145\n",
      "   Test files (unique): 7145\n",
      "   Train-Val overlap: 0 files\n",
      "   Train-Test overlap: 0 files\n",
      "   Val-Test overlap: 0 files\n",
      "   ‚úÖ SUCCESS: NO DATA LEAKAGE DETECTED!\n",
      "   üéâ Clean splits are valid for training\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VALIDATE CLEAN SPLITS - ENSURE NO DATA LEAKAGE\n",
    "# =============================================================================\n",
    "\n",
    "def validate_clean_splits(clean_split_path):\n",
    "    \"\"\"Validate that clean splits have no data leakage\"\"\"\n",
    "    \n",
    "    print(\"\\nüîç VALIDATING CLEAN SPLITS - NO DATA LEAKAGE CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Collect all base filenames from each split\n",
    "    train_files = set()\n",
    "    val_files = set()\n",
    "    test_files = set()\n",
    "    \n",
    "    for split, file_set in [('train', train_files), ('val', val_files), ('test', test_files)]:\n",
    "        split_path = os.path.join(clean_split_path, split)\n",
    "        \n",
    "        for class_name in os.listdir(split_path):\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        # For augmented files, extract original base name\n",
    "                        if img_file.startswith('TRAIN_AUG_'):\n",
    "                            # Extract original filename from augmented name\n",
    "                            base_name = '_'.join(img_file.split('_')[3:])\n",
    "                        else:\n",
    "                            # Original file\n",
    "                            base_name = img_file\n",
    "                        \n",
    "                        file_set.add(base_name)\n",
    "    \n",
    "    # Check for overlaps\n",
    "    train_val_overlap = train_files.intersection(val_files)\n",
    "    train_test_overlap = train_files.intersection(test_files)\n",
    "    val_test_overlap = val_files.intersection(test_files)\n",
    "    \n",
    "    print(f\"üìä CLEAN SPLIT VALIDATION RESULTS:\")\n",
    "    print(f\"   Train files (unique): {len(train_files)}\")\n",
    "    print(f\"   Val files (unique): {len(val_files)}\")\n",
    "    print(f\"   Test files (unique): {len(test_files)}\")\n",
    "    print(f\"   Train-Val overlap: {len(train_val_overlap)} files\")\n",
    "    print(f\"   Train-Test overlap: {len(train_test_overlap)} files\")\n",
    "    print(f\"   Val-Test overlap: {len(val_test_overlap)} files\")\n",
    "    \n",
    "    if len(train_val_overlap) == 0 and len(train_test_overlap) == 0 and len(val_test_overlap) == 0:\n",
    "        print(f\"   ‚úÖ SUCCESS: NO DATA LEAKAGE DETECTED!\")\n",
    "        print(f\"   üéâ Clean splits are valid for training\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"   ‚ùå ERROR: Data leakage still detected\")\n",
    "        return False\n",
    "\n",
    "# Validate the clean splits\n",
    "validation_success = validate_clean_splits(clean_split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4d69b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Initial data leakage validation passed\n",
      "üîç Running comprehensive pre-training validation...\n",
      "üîç COMPREHENSIVE PRE-TRAINING VALIDATION\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ CHECKING IMAGE INTEGRITY:\n",
      "----------------------------------------\n",
      "   Total images checked: 39,838\n",
      "   Corrupted/invalid images: 0\n",
      "   ‚úÖ ALL IMAGES ARE VALID\n",
      "\n",
      "2Ô∏è‚É£ CHECKING CLASS BALANCE:\n",
      "----------------------------------------\n",
      "   Classes in train: 23\n",
      "   Classes in val: 23\n",
      "   Classes in test: 23\n",
      "   All splits have same classes: True\n",
      "   Train imbalance ratio: 1.91:1\n",
      "   Val imbalance ratio: 21.37:1\n",
      "   Test imbalance ratio: 20.71:1\n",
      "   ‚úÖ CLASS DISTRIBUTION IS ACCEPTABLE\n",
      "\n",
      "3Ô∏è‚É£ CHECKING AUGMENTATION QUALITY:\n",
      "----------------------------------------\n",
      "   Augmented files checked: 100\n",
      "   Issues found: 0\n",
      "   ‚úÖ AUGMENTED IMAGES LOOK GOOD\n",
      "\n",
      "4Ô∏è‚É£ CHECKING DATASET SIZE ADEQUACY:\n",
      "----------------------------------------\n",
      "   Training samples: 25,548\n",
      "   Validation samples: 7,145\n",
      "   Test samples: 7,145\n",
      "   Number of classes: 23\n",
      "   Avg samples per class (train): 1110.8\n",
      "   Avg samples per class (val): 310.7\n",
      "   Avg samples per class (test): 310.7\n",
      "   ‚úÖ DATASET SIZE IS ADEQUATE\n",
      "\n",
      "5Ô∏è‚É£ CHECKING FOR DUPLICATE FILES:\n",
      "----------------------------------------\n",
      "      Duplicate in train: Clean_Splits\\train\\Apple___healthy\\3673d121-b5de-481c-b057-d4ee5b4959b1___RS_HL 6269.JPG\n",
      "      Duplicate in train: Clean_Splits\\train\\Apple___healthy\\9b75de13-d4b0-4b3f-988c-3e9926eef957___RS_HL 6273.JPG\n",
      "      Duplicate in train: Clean_Splits\\train\\Apple___healthy\\c21cf428-bfc3-4710-b5d2-69d1c0e94748___RS_HL 6268_flipTB.JPG\n",
      "      Duplicate in train: Clean_Splits\\train\\Apple___healthy\\dc18b924-f172-445d-8fed-61445d437aaa___RS_HL 6270.JPG\n",
      "      Duplicate in train: Clean_Splits\\train\\Tomato_healthy\\505465db-407b-4e0a-8110-7479dad5261c___GH_HL Leaf 389.JPG\n",
      "      Duplicate in train: Clean_Splits\\train\\Tomato_healthy\\cfd491d6-4af5-4728-8f0e-0d330a07174a___GH_HL Leaf 482.2.JPG\n",
      "      Duplicate in train: Clean_Splits\\train\\Tomato_healthy\\e786ac89-29fe-47e3-b49e-b9a9ee7edd9d___GH_HL Leaf 342.1.JPG\n",
      "      Duplicate in train: Clean_Splits\\train\\Tomato_Late_blight\\bd4f09bd-ee85-4ab1-bce0-8cde3fdd7f1b___GHLB_PS Leaf 23.7 Day 13.jpg\n",
      "      Duplicate in train: Clean_Splits\\train\\Tomato_Late_blight\\c1775bad-7c02-41fb-bb7d-f8df91d60ac3___GHLB_PS Leaf 23.5 Day 13.jpg\n",
      "      Duplicate in train: Clean_Splits\\train\\Tomato_Late_blight\\d81682aa-746b-4e07-af2b-52ebb6f4c017___GHLB2 Leaf 102.JPG\n",
      "      Duplicate in train: Clean_Splits\\train\\Tomato_Late_blight\\e5d707cd-077c-43af-bda9-6138e516ff51___GHLB2 Leaf 8999.JPG\n",
      "   Duplicates in train: 11\n",
      "   Duplicates in val: 0\n",
      "   Duplicates in test: 0\n",
      "   ‚ö†Ô∏è  FOUND 11 DUPLICATE FILES\n",
      "\n",
      "üéØ VALIDATION SUMMARY:\n",
      "==================================================\n",
      "Validation checks passed: 4/5\n",
      "\n",
      "   Image Integrity: ‚úÖ PASS\n",
      "   Class Balance: ‚úÖ PASS\n",
      "   Augmentation Quality: ‚úÖ PASS\n",
      "   Dataset Size: ‚úÖ PASS\n",
      "   No Duplicates: ‚ùå FAIL\n",
      "\n",
      "‚ö†Ô∏è  MINOR ISSUES DETECTED\n",
      "üü° TRAINING POSSIBLE - Monitor results carefully\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# COMPREHENSIVE PRE-TRAINING VALIDATION CHECKS\n",
    "# =============================================================================\n",
    "\n",
    "def comprehensive_pre_training_validation(clean_split_path):\n",
    "    \"\"\"Perform comprehensive validation before training\"\"\"\n",
    "    \n",
    "    print(\"üîç COMPREHENSIVE PRE-TRAINING VALIDATION\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    validation_results = {}\n",
    "    \n",
    "    # 1. VERIFY IMAGE INTEGRITY\n",
    "    print(\"\\n1Ô∏è‚É£ CHECKING IMAGE INTEGRITY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    def check_image_integrity():\n",
    "        \"\"\"Check for corrupted or invalid images\"\"\"\n",
    "        corrupted_files = []\n",
    "        total_images = 0\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_path = os.path.join(clean_split_path, split)\n",
    "            for class_name in os.listdir(split_path):\n",
    "                class_path = os.path.join(split_path, class_name)\n",
    "                if os.path.isdir(class_path):\n",
    "                    for img_file in os.listdir(class_path):\n",
    "                        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                            img_path = os.path.join(class_path, img_file)\n",
    "                            total_images += 1\n",
    "                            \n",
    "                            try:\n",
    "                                # Try to read image\n",
    "                                img = cv2.imread(img_path)\n",
    "                                if img is None:\n",
    "                                    corrupted_files.append(img_path)\n",
    "                                elif img.shape[0] < 32 or img.shape[1] < 32:  # Too small\n",
    "                                    corrupted_files.append(img_path)\n",
    "                            except Exception as e:\n",
    "                                corrupted_files.append(img_path)\n",
    "        \n",
    "        print(f\"   Total images checked: {total_images:,}\")\n",
    "        print(f\"   Corrupted/invalid images: {len(corrupted_files)}\")\n",
    "        \n",
    "        if len(corrupted_files) == 0:\n",
    "            print(\"   ‚úÖ ALL IMAGES ARE VALID\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  FOUND {len(corrupted_files)} PROBLEMATIC IMAGES\")\n",
    "            for file_path in corrupted_files[:5]:  # Show first 5\n",
    "                print(f\"      - {file_path}\")\n",
    "            if len(corrupted_files) > 5:\n",
    "                print(f\"      ... and {len(corrupted_files) - 5} more\")\n",
    "            return False\n",
    "    \n",
    "    validation_results['image_integrity'] = check_image_integrity()\n",
    "    \n",
    "    # 2. CHECK CLASS BALANCE AND DISTRIBUTION\n",
    "    print(\"\\n2Ô∏è‚É£ CHECKING CLASS BALANCE:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    def check_class_balance():\n",
    "        \"\"\"Check class distribution across splits\"\"\"\n",
    "        split_distributions = {}\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_path = os.path.join(clean_split_path, split)\n",
    "            class_counts = {}\n",
    "            \n",
    "            for class_name in os.listdir(split_path):\n",
    "                class_path = os.path.join(split_path, class_name)\n",
    "                if os.path.isdir(class_path):\n",
    "                    count = len([f for f in os.listdir(class_path) \n",
    "                               if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                    class_counts[class_name] = count\n",
    "            \n",
    "            split_distributions[split] = class_counts\n",
    "        \n",
    "        # Check if all splits have the same classes\n",
    "        train_classes = set(split_distributions['train'].keys())\n",
    "        val_classes = set(split_distributions['val'].keys())\n",
    "        test_classes = set(split_distributions['test'].keys())\n",
    "        \n",
    "        all_classes_consistent = (train_classes == val_classes == test_classes)\n",
    "        \n",
    "        # Calculate imbalance ratios\n",
    "        train_counts = list(split_distributions['train'].values())\n",
    "        val_counts = list(split_distributions['val'].values())\n",
    "        test_counts = list(split_distributions['test'].values())\n",
    "        \n",
    "        train_imbalance = max(train_counts) / min(train_counts) if min(train_counts) > 0 else float('inf')\n",
    "        val_imbalance = max(val_counts) / min(val_counts) if min(val_counts) > 0 else float('inf')\n",
    "        test_imbalance = max(test_counts) / min(test_counts) if min(test_counts) > 0 else float('inf')\n",
    "        \n",
    "        print(f\"   Classes in train: {len(train_classes)}\")\n",
    "        print(f\"   Classes in val: {len(val_classes)}\")\n",
    "        print(f\"   Classes in test: {len(test_classes)}\")\n",
    "        print(f\"   All splits have same classes: {all_classes_consistent}\")\n",
    "        print(f\"   Train imbalance ratio: {train_imbalance:.2f}:1\")\n",
    "        print(f\"   Val imbalance ratio: {val_imbalance:.2f}:1\")\n",
    "        print(f\"   Test imbalance ratio: {test_imbalance:.2f}:1\")\n",
    "        \n",
    "        # Check for classes with too few samples\n",
    "        min_samples_per_class = 5\n",
    "        problematic_classes = []\n",
    "        \n",
    "        for split, counts in split_distributions.items():\n",
    "            for class_name, count in counts.items():\n",
    "                if count < min_samples_per_class:\n",
    "                    problematic_classes.append(f\"{split}/{class_name}: {count} samples\")\n",
    "        \n",
    "        if len(problematic_classes) > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  CLASSES WITH TOO FEW SAMPLES:\")\n",
    "            for prob_class in problematic_classes[:10]:  # Show first 10\n",
    "                print(f\"      - {prob_class}\")\n",
    "        \n",
    "        # Overall assessment\n",
    "        balance_ok = (all_classes_consistent and \n",
    "                     train_imbalance < 10 and \n",
    "                     len(problematic_classes) == 0)\n",
    "        \n",
    "        if balance_ok:\n",
    "            print(\"   ‚úÖ CLASS DISTRIBUTION IS ACCEPTABLE\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  CLASS DISTRIBUTION ISSUES DETECTED\")\n",
    "        \n",
    "        return balance_ok, split_distributions\n",
    "    \n",
    "    balance_ok, split_distributions = check_class_balance()\n",
    "    validation_results['class_balance'] = balance_ok\n",
    "    \n",
    "    # 3. CHECK AUGMENTATION QUALITY\n",
    "    print(\"\\n3Ô∏è‚É£ CHECKING AUGMENTATION QUALITY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    def check_augmentation_quality():\n",
    "        \"\"\"Check if augmented images are reasonable\"\"\"\n",
    "        train_path = os.path.join(clean_split_path, 'train')\n",
    "        aug_issues = []\n",
    "        \n",
    "        # Sample some augmented images to check\n",
    "        aug_files_checked = 0\n",
    "        max_check = 100  # Check up to 100 augmented files\n",
    "        \n",
    "        for class_name in os.listdir(train_path):\n",
    "            class_path = os.path.join(train_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                aug_files = [f for f in os.listdir(class_path) \n",
    "                           if f.startswith('TRAIN_AUG_')]\n",
    "                \n",
    "                for aug_file in aug_files[:10]:  # Check up to 10 per class\n",
    "                    if aug_files_checked >= max_check:\n",
    "                        break\n",
    "                    \n",
    "                    aug_path = os.path.join(class_path, aug_file)\n",
    "                    try:\n",
    "                        img = cv2.imread(aug_path)\n",
    "                        if img is None:\n",
    "                            aug_issues.append(f\"Cannot read: {aug_path}\")\n",
    "                        elif img.shape[0] < 32 or img.shape[1] < 32:\n",
    "                            aug_issues.append(f\"Too small: {aug_path}\")\n",
    "                        # Add more quality checks if needed\n",
    "                        aug_files_checked += 1\n",
    "                    except Exception as e:\n",
    "                        aug_issues.append(f\"Error reading: {aug_path}\")\n",
    "                \n",
    "                if aug_files_checked >= max_check:\n",
    "                    break\n",
    "        \n",
    "        print(f\"   Augmented files checked: {aug_files_checked}\")\n",
    "        print(f\"   Issues found: {len(aug_issues)}\")\n",
    "        \n",
    "        if len(aug_issues) == 0:\n",
    "            print(\"   ‚úÖ AUGMENTED IMAGES LOOK GOOD\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  AUGMENTATION QUALITY ISSUES:\")\n",
    "            for issue in aug_issues[:5]:\n",
    "                print(f\"      - {issue}\")\n",
    "            return False\n",
    "    \n",
    "    validation_results['augmentation_quality'] = check_augmentation_quality()\n",
    "    \n",
    "    # 4. CHECK DATASET SIZE ADEQUACY\n",
    "    print(\"\\n4Ô∏è‚É£ CHECKING DATASET SIZE ADEQUACY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    def check_dataset_size():\n",
    "        \"\"\"Check if dataset size is adequate for training\"\"\"\n",
    "        total_train = sum(split_distributions['train'].values())\n",
    "        total_val = sum(split_distributions['val'].values())\n",
    "        total_test = sum(split_distributions['test'].values())\n",
    "        num_classes = len(split_distributions['train'])\n",
    "        \n",
    "        samples_per_class_train = total_train / num_classes\n",
    "        samples_per_class_val = total_val / num_classes\n",
    "        samples_per_class_test = total_test / num_classes\n",
    "        \n",
    "        print(f\"   Training samples: {total_train:,}\")\n",
    "        print(f\"   Validation samples: {total_val:,}\")\n",
    "        print(f\"   Test samples: {total_test:,}\")\n",
    "        print(f\"   Number of classes: {num_classes}\")\n",
    "        print(f\"   Avg samples per class (train): {samples_per_class_train:.1f}\")\n",
    "        print(f\"   Avg samples per class (val): {samples_per_class_val:.1f}\")\n",
    "        print(f\"   Avg samples per class (test): {samples_per_class_test:.1f}\")\n",
    "        \n",
    "        # Adequacy thresholds\n",
    "        min_train_per_class = 50\n",
    "        min_val_per_class = 10\n",
    "        min_test_per_class = 10\n",
    "        \n",
    "        adequate = (samples_per_class_train >= min_train_per_class and\n",
    "                   samples_per_class_val >= min_val_per_class and\n",
    "                   samples_per_class_test >= min_test_per_class)\n",
    "        \n",
    "        if adequate:\n",
    "            print(\"   ‚úÖ DATASET SIZE IS ADEQUATE\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  DATASET MIGHT BE TOO SMALL FOR ROBUST TRAINING\")\n",
    "        \n",
    "        return adequate\n",
    "    \n",
    "    validation_results['dataset_size'] = check_dataset_size()\n",
    "    \n",
    "    # 5. VERIFY NO DUPLICATE FILES\n",
    "    print(\"\\n5Ô∏è‚É£ CHECKING FOR DUPLICATE FILES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    def check_duplicates():\n",
    "        \"\"\"Check for duplicate files within each split\"\"\"\n",
    "        import hashlib\n",
    "        \n",
    "        def get_file_hash(file_path):\n",
    "            \"\"\"Get MD5 hash of file\"\"\"\n",
    "            hash_md5 = hashlib.md5()\n",
    "            try:\n",
    "                with open(file_path, \"rb\") as f:\n",
    "                    for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                        hash_md5.update(chunk)\n",
    "                return hash_md5.hexdigest()\n",
    "            except:\n",
    "                return None\n",
    "        \n",
    "        duplicates_found = 0\n",
    "        \n",
    "        for split in ['train', 'val', 'test']:\n",
    "            split_path = os.path.join(clean_split_path, split)\n",
    "            file_hashes = {}\n",
    "            split_duplicates = 0\n",
    "            \n",
    "            for class_name in os.listdir(split_path):\n",
    "                class_path = os.path.join(split_path, class_name)\n",
    "                if os.path.isdir(class_path):\n",
    "                    for img_file in os.listdir(class_path):\n",
    "                        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                            img_path = os.path.join(class_path, img_file)\n",
    "                            file_hash = get_file_hash(img_path)\n",
    "                            \n",
    "                            if file_hash and file_hash in file_hashes:\n",
    "                                split_duplicates += 1\n",
    "                                print(f\"      Duplicate in {split}: {img_path}\")\n",
    "                            elif file_hash:\n",
    "                                file_hashes[file_hash] = img_path\n",
    "            \n",
    "            print(f\"   Duplicates in {split}: {split_duplicates}\")\n",
    "            duplicates_found += split_duplicates\n",
    "        \n",
    "        if duplicates_found == 0:\n",
    "            print(\"   ‚úÖ NO DUPLICATE FILES FOUND\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  FOUND {duplicates_found} DUPLICATE FILES\")\n",
    "            return False\n",
    "    \n",
    "    validation_results['no_duplicates'] = check_duplicates()\n",
    "    \n",
    "    # 6. FINAL VALIDATION SUMMARY\n",
    "    print(\"\\nüéØ VALIDATION SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    passed_checks = sum(validation_results.values())\n",
    "    total_checks = len(validation_results)\n",
    "    \n",
    "    print(f\"Validation checks passed: {passed_checks}/{total_checks}\")\n",
    "    print()\n",
    "    \n",
    "    for check_name, passed in validation_results.items():\n",
    "        status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n",
    "        check_display = check_name.replace('_', ' ').title()\n",
    "        print(f\"   {check_display}: {status}\")\n",
    "    \n",
    "    # Overall recommendation\n",
    "    if passed_checks == total_checks:\n",
    "        print(f\"\\nüéâ ALL VALIDATIONS PASSED!\")\n",
    "        print(\"‚úÖ READY FOR TRAINING - Dataset is clean and robust\")\n",
    "        recommendation = \"PROCEED_WITH_TRAINING\"\n",
    "    elif passed_checks >= total_checks - 1:\n",
    "        print(f\"\\n‚ö†Ô∏è  MINOR ISSUES DETECTED\")\n",
    "        print(\"üü° TRAINING POSSIBLE - Monitor results carefully\")\n",
    "        recommendation = \"PROCEED_WITH_CAUTION\"\n",
    "    else:\n",
    "        print(f\"\\nüö® SIGNIFICANT ISSUES DETECTED\")\n",
    "        print(\"‚ùå FIX ISSUES BEFORE TRAINING\")\n",
    "        recommendation = \"FIX_ISSUES_FIRST\"\n",
    "    \n",
    "    return recommendation, validation_results\n",
    "\n",
    "# Execute comprehensive validation\n",
    "if validation_success:\n",
    "    print(\"‚úÖ Initial data leakage validation passed\")\n",
    "    print(\"üîç Running comprehensive pre-training validation...\")\n",
    "    training_recommendation, detailed_validation = comprehensive_pre_training_validation(clean_split_path)\n",
    "else:\n",
    "    print(\"‚ùå Fix data leakage issues first before proceeding\")\n",
    "    training_recommendation = \"FIX_DATA_LEAKAGE_FIRST\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6bb524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ FINAL TRAINING READINESS ASSESSMENT\n",
      "============================================================\n",
      "üü° STATUS: PROCEED WITH CAUTION\n",
      "‚ö†Ô∏è  Minor issues detected, but training is possible\n",
      "‚úÖ Data leakage is fixed\n",
      "‚ö†Ô∏è  Some validation checks flagged concerns\n",
      "\n",
      "‚ö†Ô∏è  RECOMMENDATIONS:\n",
      "   1. Proceed with training but monitor closely\n",
      "   2. Use more conservative hyperparameters\n",
      "   3. Implement extra validation during training\n",
      "   4. Be prepared to stop and fix issues if needed\n",
      "\n",
      "============================================================\n",
      "üéâ VALIDATION COMPLETE - READY TO TRAIN!\n",
      "You can now proceed with confidence that your results will be legitimate.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL TRAINING READINESS ASSESSMENT\n",
    "# =============================================================================\n",
    "\n",
    "def final_training_readiness_assessment():\n",
    "    \"\"\"Final assessment before training\"\"\"\n",
    "    \n",
    "    print(\"\\nüéØ FINAL TRAINING READINESS ASSESSMENT\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if training_recommendation == \"PROCEED_WITH_TRAINING\":\n",
    "        print(\"üü¢ STATUS: READY FOR TRAINING\")\n",
    "        print(\"‚úÖ All validation checks passed\")\n",
    "        print(\"‚úÖ Dataset is clean and properly structured\")\n",
    "        print(\"‚úÖ No data leakage detected\")\n",
    "        print(\"‚úÖ Class distribution is reasonable\")\n",
    "        print(\"‚úÖ Images are valid and accessible\")\n",
    "        \n",
    "        print(f\"\\nüöÄ RECOMMENDED NEXT STEPS:\")\n",
    "        print(\"   1. Proceed with model training\")\n",
    "        print(\"   2. Monitor training curves carefully\")\n",
    "        print(\"   3. Use early stopping and learning rate reduction\")\n",
    "        print(\"   4. Save best model based on validation loss\")\n",
    "        print(\"   5. Evaluate on test set only after training is complete\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    elif training_recommendation == \"PROCEED_WITH_CAUTION\":\n",
    "        print(\"üü° STATUS: PROCEED WITH CAUTION\")\n",
    "        print(\"‚ö†Ô∏è  Minor issues detected, but training is possible\")\n",
    "        print(\"‚úÖ Data leakage is fixed\")\n",
    "        print(\"‚ö†Ô∏è  Some validation checks flagged concerns\")\n",
    "        \n",
    "        print(f\"\\n‚ö†Ô∏è  RECOMMENDATIONS:\")\n",
    "        print(\"   1. Proceed with training but monitor closely\")\n",
    "        print(\"   2. Use more conservative hyperparameters\")\n",
    "        print(\"   3. Implement extra validation during training\")\n",
    "        print(\"   4. Be prepared to stop and fix issues if needed\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    else:\n",
    "        print(\"üî¥ STATUS: NOT READY FOR TRAINING\")\n",
    "        print(\"‚ùå Significant issues must be fixed first\")\n",
    "        \n",
    "        print(f\"\\nüõ†Ô∏è  REQUIRED FIXES:\")\n",
    "        if not detailed_validation.get('image_integrity', True):\n",
    "            print(\"   - Fix corrupted or invalid images\")\n",
    "        if not detailed_validation.get('class_balance', True):\n",
    "            print(\"   - Address class imbalance issues\")\n",
    "        if not detailed_validation.get('augmentation_quality', True):\n",
    "            print(\"   - Fix augmentation quality problems\")\n",
    "        if not detailed_validation.get('dataset_size', True):\n",
    "            print(\"   - Increase dataset size or reduce number of classes\")\n",
    "        if not detailed_validation.get('no_duplicates', True):\n",
    "            print(\"   - Remove duplicate files\")\n",
    "        \n",
    "        return False\n",
    "\n",
    "# Final assessment\n",
    "training_ready = final_training_readiness_assessment()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "if training_ready:\n",
    "    print(\"üéâ VALIDATION COMPLETE - READY TO TRAIN!\")\n",
    "    print(\"You can now proceed with confidence that your results will be legitimate.\")\n",
    "else:\n",
    "    print(\"üõë VALIDATION INCOMPLETE - PLEASE FIX ISSUES FIRST\")\n",
    "    print(\"Address the flagged issues before training to ensure valid results.\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4249e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0454de40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ CLEANING UP DUPLICATES AND FINALIZING DATASET\n",
      "============================================================\n",
      "üîç Checking train split for duplicates...\n",
      "   ‚úÖ Removed duplicate: 3673d121-b5de-481c-b057-d4ee5b4959b1___RS_HL 6269.JPG\n",
      "   ‚úÖ Removed duplicate: 9b75de13-d4b0-4b3f-988c-3e9926eef957___RS_HL 6273.JPG\n",
      "   ‚úÖ Removed duplicate: c21cf428-bfc3-4710-b5d2-69d1c0e94748___RS_HL 6268_flipTB.JPG\n",
      "   ‚úÖ Removed duplicate: dc18b924-f172-445d-8fed-61445d437aaa___RS_HL 6270.JPG\n",
      "   ‚úÖ Removed duplicate: 505465db-407b-4e0a-8110-7479dad5261c___GH_HL Leaf 389.JPG\n",
      "   ‚úÖ Removed duplicate: cfd491d6-4af5-4728-8f0e-0d330a07174a___GH_HL Leaf 482.2.JPG\n",
      "   ‚úÖ Removed duplicate: e786ac89-29fe-47e3-b49e-b9a9ee7edd9d___GH_HL Leaf 342.1.JPG\n",
      "   ‚úÖ Removed duplicate: bd4f09bd-ee85-4ab1-bce0-8cde3fdd7f1b___GHLB_PS Leaf 23.7 Day 13.jpg\n",
      "   ‚úÖ Removed duplicate: c1775bad-7c02-41fb-bb7d-f8df91d60ac3___GHLB_PS Leaf 23.5 Day 13.jpg\n",
      "   ‚úÖ Removed duplicate: d81682aa-746b-4e07-af2b-52ebb6f4c017___GHLB2 Leaf 102.JPG\n",
      "   ‚úÖ Removed duplicate: e5d707cd-077c-43af-bda9-6138e516ff51___GHLB2 Leaf 8999.JPG\n",
      "üîç Checking val split for duplicates...\n",
      "üîç Checking test split for duplicates...\n",
      "\n",
      "üéØ CLEANUP RESULTS:\n",
      "   Duplicates removed: 11\n",
      "   ‚úÖ Dataset is now clean and ready for training!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLEAN UP DUPLICATES AND PREPARE FOR TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "def clean_up_duplicates_and_finalize(clean_split_path):\n",
    "    \"\"\"Clean up any remaining duplicates and prepare for training\"\"\"\n",
    "    \n",
    "    print(\"üßπ CLEANING UP DUPLICATES AND FINALIZING DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    import hashlib\n",
    "    \n",
    "    def get_file_hash(file_path):\n",
    "        \"\"\"Get MD5 hash of file\"\"\"\n",
    "        hash_md5 = hashlib.md5()\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                    hash_md5.update(chunk)\n",
    "            return hash_md5.hexdigest()\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    duplicates_removed = 0\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(clean_split_path, split)\n",
    "        file_hashes = {}\n",
    "        \n",
    "        print(f\"üîç Checking {split} split for duplicates...\")\n",
    "        \n",
    "        for class_name in os.listdir(split_path):\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                files_to_remove = []\n",
    "                \n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        img_path = os.path.join(class_path, img_file)\n",
    "                        file_hash = get_file_hash(img_path)\n",
    "                        \n",
    "                        if file_hash and file_hash in file_hashes:\n",
    "                            files_to_remove.append(img_path)\n",
    "                            duplicates_removed += 1\n",
    "                        elif file_hash:\n",
    "                            file_hashes[file_hash] = img_path\n",
    "                \n",
    "                # Remove duplicates\n",
    "                for duplicate_file in files_to_remove:\n",
    "                    try:\n",
    "                        os.remove(duplicate_file)\n",
    "                        print(f\"   ‚úÖ Removed duplicate: {os.path.basename(duplicate_file)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ‚ùå Error removing {duplicate_file}: {e}\")\n",
    "    \n",
    "    print(f\"\\nüéØ CLEANUP RESULTS:\")\n",
    "    print(f\"   Duplicates removed: {duplicates_removed}\")\n",
    "    \n",
    "    if duplicates_removed > 0:\n",
    "        print(\"   ‚úÖ Dataset is now clean and ready for training!\")\n",
    "    else:\n",
    "        print(\"   ‚úÖ No duplicates found - dataset was already clean!\")\n",
    "    \n",
    "    return duplicates_removed\n",
    "\n",
    "# Clean up duplicates\n",
    "duplicates_removed = clean_up_duplicates_and_finalize(clean_split_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bc5d5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Running re-validation after duplicate cleanup...\n",
      "\n",
      "üîÑ RE-VALIDATING AFTER DUPLICATE CLEANUP\n",
      "============================================================\n",
      "\n",
      "1Ô∏è‚É£ RE-CHECKING FOR DUPLICATES:\n",
      "----------------------------------------\n",
      "   Duplicates in train: 0\n",
      "   Duplicates in val: 0\n",
      "   Duplicates in test: 0\n",
      "   ‚úÖ NO DUPLICATE FILES FOUND - CLEANUP SUCCESSFUL!\n",
      "\n",
      "2Ô∏è‚É£ RE-CHECKING DATA LEAKAGE:\n",
      "----------------------------------------\n",
      "   Train files (unique): 21424\n",
      "   Val files (unique): 7145\n",
      "   Test files (unique): 7145\n",
      "   Train-Val overlap: 0 files\n",
      "   Train-Test overlap: 0 files\n",
      "   Val-Test overlap: 0 files\n",
      "   ‚úÖ NO DATA LEAKAGE DETECTED!\n",
      "\n",
      "3Ô∏è‚É£ UPDATED DATASET STATISTICS:\n",
      "----------------------------------------\n",
      "   Train: 25,537 images\n",
      "   Val: 7,145 images\n",
      "   Test: 7,145 images\n",
      "   Total images: 39,827\n",
      "   Classes: 23\n",
      "\n",
      "4Ô∏è‚É£ CLASS BALANCE AFTER CLEANUP:\n",
      "----------------------------------------\n",
      "   Train imbalance ratio: 1.92:1\n",
      "   Val imbalance ratio: 21.37:1\n",
      "   Test imbalance ratio: 20.71:1\n",
      "   ‚úÖ ALL CLASSES HAVE ADEQUATE SAMPLES\n",
      "\n",
      "5Ô∏è‚É£ CHECKING DATASET SIZE ADEQUACY AFTER CLEANUP:\n",
      "----------------------------------------\n",
      "   Training samples: 25,537\n",
      "   Validation samples: 7,145\n",
      "   Test samples: 7,145\n",
      "   Number of classes: 23\n",
      "   Avg samples per class (train): 1110.3\n",
      "   Avg samples per class (val): 310.7\n",
      "   Avg samples per class (test): 310.7\n",
      "   ‚úÖ DATASET SIZE IS ADEQUATE\n",
      "\n",
      "üéØ POST-CLEANUP VALIDATION SUMMARY:\n",
      "==================================================\n",
      "Validation checks passed: 4/4\n",
      "\n",
      "   No Duplicates: ‚úÖ PASS\n",
      "   No Data Leakage: ‚úÖ PASS\n",
      "   Adequate Samples: ‚úÖ PASS\n",
      "   Dataset Size: ‚úÖ PASS\n",
      "\n",
      "üéâ ALL POST-CLEANUP VALIDATIONS PASSED!\n",
      "‚úÖ DATASET IS NOW FULLY CLEAN AND READY FOR TRAINING\n",
      "\n",
      "======================================================================\n",
      "üéØ FINAL DATASET STATUS REPORT\n",
      "======================================================================\n",
      "üü¢ STATUS: READY FOR TRAINING\n",
      "‚úÖ All issues have been resolved\n",
      "‚úÖ Dataset is clean, balanced, and leak-free\n",
      "‚úÖ You can now train with confidence!\n",
      "\n",
      "üìä FINAL DATASET SUMMARY:\n",
      "   Total images: 39,827\n",
      "   Training: 25,537\n",
      "   Validation: 7,145\n",
      "   Test: 7,145\n",
      "   Classes: 23\n",
      "   Duplicates removed: 11\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# RE-VALIDATE AFTER DUPLICATE CLEANUP - FIXED VERSION\n",
    "# =============================================================================\n",
    "\n",
    "def re_validate_after_cleanup(clean_split_path):\n",
    "    \"\"\"Re-run validation after cleaning up duplicates\"\"\"\n",
    "    \n",
    "    print(\"\\nüîÑ RE-VALIDATING AFTER DUPLICATE CLEANUP\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Re-run the comprehensive validation\n",
    "    validation_results = {}\n",
    "    \n",
    "    # 1. Re-check for duplicates\n",
    "    print(\"\\n1Ô∏è‚É£ RE-CHECKING FOR DUPLICATES:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    import hashlib\n",
    "    \n",
    "    def get_file_hash(file_path):\n",
    "        \"\"\"Get MD5 hash of file\"\"\"\n",
    "        hash_md5 = hashlib.md5()\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                    hash_md5.update(chunk)\n",
    "            return hash_md5.hexdigest()\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    duplicates_found = 0\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(clean_split_path, split)\n",
    "        file_hashes = {}\n",
    "        split_duplicates = 0\n",
    "        \n",
    "        for class_name in os.listdir(split_path):\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        img_path = os.path.join(class_path, img_file)\n",
    "                        file_hash = get_file_hash(img_path)\n",
    "                        \n",
    "                        if file_hash and file_hash in file_hashes:\n",
    "                            split_duplicates += 1\n",
    "                            print(f\"      Duplicate in {split}: {img_path}\")\n",
    "                        elif file_hash:\n",
    "                            file_hashes[file_hash] = img_path\n",
    "        \n",
    "        print(f\"   Duplicates in {split}: {split_duplicates}\")\n",
    "        duplicates_found += split_duplicates\n",
    "    \n",
    "    if duplicates_found == 0:\n",
    "        print(\"   ‚úÖ NO DUPLICATE FILES FOUND - CLEANUP SUCCESSFUL!\")\n",
    "        validation_results['no_duplicates'] = True\n",
    "    else:\n",
    "        print(f\"   ‚ùå STILL FOUND {duplicates_found} DUPLICATE FILES\")\n",
    "        validation_results['no_duplicates'] = False\n",
    "    \n",
    "    # 2. Re-check data leakage\n",
    "    print(\"\\n2Ô∏è‚É£ RE-CHECKING DATA LEAKAGE:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Collect all base filenames from each split\n",
    "    train_files = set()\n",
    "    val_files = set()\n",
    "    test_files = set()\n",
    "    \n",
    "    for split, file_set in [('train', train_files), ('val', val_files), ('test', test_files)]:\n",
    "        split_path = os.path.join(clean_split_path, split)\n",
    "        \n",
    "        for class_name in os.listdir(split_path):\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                for img_file in os.listdir(class_path):\n",
    "                    if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                        # For augmented files, extract original base name\n",
    "                        if img_file.startswith('TRAIN_AUG_'):\n",
    "                            # Extract original filename from augmented name\n",
    "                            base_name = '_'.join(img_file.split('_')[3:])\n",
    "                        else:\n",
    "                            # Original file\n",
    "                            base_name = img_file\n",
    "                        \n",
    "                        file_set.add(base_name)\n",
    "    \n",
    "    # Check for overlaps\n",
    "    train_val_overlap = train_files.intersection(val_files)\n",
    "    train_test_overlap = train_files.intersection(test_files)\n",
    "    val_test_overlap = val_files.intersection(test_files)\n",
    "    \n",
    "    print(f\"   Train files (unique): {len(train_files)}\")\n",
    "    print(f\"   Val files (unique): {len(val_files)}\")\n",
    "    print(f\"   Test files (unique): {len(test_files)}\")\n",
    "    print(f\"   Train-Val overlap: {len(train_val_overlap)} files\")\n",
    "    print(f\"   Train-Test overlap: {len(train_test_overlap)} files\")\n",
    "    print(f\"   Val-Test overlap: {len(val_test_overlap)} files\")\n",
    "    \n",
    "    if len(train_val_overlap) == 0 and len(train_test_overlap) == 0 and len(val_test_overlap) == 0:\n",
    "        print(f\"   ‚úÖ NO DATA LEAKAGE DETECTED!\")\n",
    "        validation_results['no_data_leakage'] = True\n",
    "    else:\n",
    "        print(f\"   ‚ùå DATA LEAKAGE STILL DETECTED\")\n",
    "        validation_results['no_data_leakage'] = False\n",
    "    \n",
    "    # 3. Get updated dataset statistics (THIS IS THE MISSING PIECE!)\n",
    "    print(\"\\n3Ô∏è‚É£ UPDATED DATASET STATISTICS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_images = 0\n",
    "    split_stats = {}\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_path = os.path.join(clean_split_path, split)\n",
    "        split_count = 0\n",
    "        class_counts = {}\n",
    "        \n",
    "        for class_name in os.listdir(split_path):\n",
    "            class_path = os.path.join(split_path, class_name)\n",
    "            if os.path.isdir(class_path):\n",
    "                count = len([f for f in os.listdir(class_path) \n",
    "                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "                class_counts[class_name] = count\n",
    "                split_count += count\n",
    "        \n",
    "        split_stats[split] = {\n",
    "            'total': split_count,\n",
    "            'classes': class_counts\n",
    "        }\n",
    "        total_images += split_count\n",
    "        \n",
    "        print(f\"   {split.capitalize()}: {split_count:,} images\")\n",
    "    \n",
    "    print(f\"   Total images: {total_images:,}\")\n",
    "    print(f\"   Classes: {len(split_stats['train']['classes'])}\")\n",
    "    \n",
    "    # 4. Check class balance after cleanup (NOW USING THE LOCAL split_stats!)\n",
    "    print(\"\\n4Ô∏è‚É£ CLASS BALANCE AFTER CLEANUP:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    train_counts = list(split_stats['train']['classes'].values())\n",
    "    val_counts = list(split_stats['val']['classes'].values())\n",
    "    test_counts = list(split_stats['test']['classes'].values())\n",
    "    \n",
    "    train_imbalance = max(train_counts) / min(train_counts) if min(train_counts) > 0 else float('inf')\n",
    "    val_imbalance = max(val_counts) / min(val_counts) if min(val_counts) > 0 else float('inf')\n",
    "    test_imbalance = max(test_counts) / min(test_counts) if min(test_counts) > 0 else float('inf')\n",
    "    \n",
    "    print(f\"   Train imbalance ratio: {train_imbalance:.2f}:1\")\n",
    "    print(f\"   Val imbalance ratio: {val_imbalance:.2f}:1\")\n",
    "    print(f\"   Test imbalance ratio: {test_imbalance:.2f}:1\")\n",
    "    \n",
    "    # Check for classes with too few samples after cleanup\n",
    "    min_samples_per_class = 5\n",
    "    problematic_classes = []\n",
    "    \n",
    "    for split, stats in split_stats.items():\n",
    "        for class_name, count in stats['classes'].items():\n",
    "            if count < min_samples_per_class:\n",
    "                problematic_classes.append(f\"{split}/{class_name}: {count} samples\")\n",
    "    \n",
    "    if len(problematic_classes) > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  CLASSES WITH TOO FEW SAMPLES:\")\n",
    "        for prob_class in problematic_classes[:10]:\n",
    "            print(f\"      - {prob_class}\")\n",
    "        validation_results['adequate_samples'] = False\n",
    "    else:\n",
    "        print(f\"   ‚úÖ ALL CLASSES HAVE ADEQUATE SAMPLES\")\n",
    "        validation_results['adequate_samples'] = True\n",
    "    \n",
    "    # 5. Check dataset size adequacy after cleanup\n",
    "    print(\"\\n5Ô∏è‚É£ CHECKING DATASET SIZE ADEQUACY AFTER CLEANUP:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_train = sum(split_stats['train']['classes'].values())\n",
    "    total_val = sum(split_stats['val']['classes'].values())\n",
    "    total_test = sum(split_stats['test']['classes'].values())\n",
    "    num_classes = len(split_stats['train']['classes'])\n",
    "    \n",
    "    samples_per_class_train = total_train / num_classes\n",
    "    samples_per_class_val = total_val / num_classes\n",
    "    samples_per_class_test = total_test / num_classes\n",
    "    \n",
    "    print(f\"   Training samples: {total_train:,}\")\n",
    "    print(f\"   Validation samples: {total_val:,}\")\n",
    "    print(f\"   Test samples: {total_test:,}\")\n",
    "    print(f\"   Number of classes: {num_classes}\")\n",
    "    print(f\"   Avg samples per class (train): {samples_per_class_train:.1f}\")\n",
    "    print(f\"   Avg samples per class (val): {samples_per_class_val:.1f}\")\n",
    "    print(f\"   Avg samples per class (test): {samples_per_class_test:.1f}\")\n",
    "    \n",
    "    # Adequacy thresholds\n",
    "    min_train_per_class = 50\n",
    "    min_val_per_class = 10\n",
    "    min_test_per_class = 10\n",
    "    \n",
    "    size_adequate = (samples_per_class_train >= min_train_per_class and\n",
    "                    samples_per_class_val >= min_val_per_class and\n",
    "                    samples_per_class_test >= min_test_per_class)\n",
    "    \n",
    "    if size_adequate:\n",
    "        print(\"   ‚úÖ DATASET SIZE IS ADEQUATE\")\n",
    "        validation_results['dataset_size'] = True\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  DATASET MIGHT BE TOO SMALL FOR ROBUST TRAINING\")\n",
    "        validation_results['dataset_size'] = False\n",
    "    \n",
    "    # 6. Final validation summary\n",
    "    print(\"\\nüéØ POST-CLEANUP VALIDATION SUMMARY:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    passed_checks = sum(validation_results.values())\n",
    "    total_checks = len(validation_results)\n",
    "    \n",
    "    print(f\"Validation checks passed: {passed_checks}/{total_checks}\")\n",
    "    print()\n",
    "    \n",
    "    for check_name, passed in validation_results.items():\n",
    "        status = \"‚úÖ PASS\" if passed else \"‚ùå FAIL\"\n",
    "        check_display = check_name.replace('_', ' ').title()\n",
    "        print(f\"   {check_display}: {status}\")\n",
    "    \n",
    "    # Final recommendation\n",
    "    if passed_checks == total_checks:\n",
    "        print(f\"\\nüéâ ALL POST-CLEANUP VALIDATIONS PASSED!\")\n",
    "        print(\"‚úÖ DATASET IS NOW FULLY CLEAN AND READY FOR TRAINING\")\n",
    "        final_recommendation = \"PROCEED_WITH_TRAINING\"\n",
    "    elif passed_checks >= total_checks - 1:\n",
    "        print(f\"\\n‚ö†Ô∏è  MINOR ISSUES REMAIN\")\n",
    "        print(\"üü° TRAINING POSSIBLE BUT MONITOR CAREFULLY\")\n",
    "        final_recommendation = \"PROCEED_WITH_CAUTION\"\n",
    "    else:\n",
    "        print(f\"\\nüö® SIGNIFICANT ISSUES REMAIN\")\n",
    "        print(\"‚ùå ADDITIONAL FIXES NEEDED BEFORE TRAINING\")\n",
    "        final_recommendation = \"FIX_REMAINING_ISSUES\"\n",
    "    \n",
    "    return final_recommendation, validation_results, split_stats\n",
    "\n",
    "# Execute re-validation after cleanup\n",
    "print(\"üîÑ Running re-validation after duplicate cleanup...\")\n",
    "final_recommendation, post_cleanup_validation, updated_stats = re_validate_after_cleanup(clean_split_path)\n",
    "\n",
    "# Final status report\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üéØ FINAL DATASET STATUS REPORT\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "if final_recommendation == \"PROCEED_WITH_TRAINING\":\n",
    "    print(\"üü¢ STATUS: READY FOR TRAINING\")\n",
    "    print(\"‚úÖ All issues have been resolved\")\n",
    "    print(\"‚úÖ Dataset is clean, balanced, and leak-free\")\n",
    "    print(\"‚úÖ You can now train with confidence!\")\n",
    "    \n",
    "elif final_recommendation == \"PROCEED_WITH_CAUTION\":\n",
    "    print(\"üü° STATUS: PROCEED WITH CAUTION\")\n",
    "    print(\"‚ö†Ô∏è  Minor issues remain but training is possible\")\n",
    "    print(\"üîç Monitor training carefully for any anomalies\")\n",
    "    \n",
    "else:\n",
    "    print(\"üî¥ STATUS: ADDITIONAL FIXES NEEDED\")\n",
    "    print(\"‚ùå Please address remaining issues before training\")\n",
    "\n",
    "print(f\"\\nüìä FINAL DATASET SUMMARY:\")\n",
    "print(f\"   Total images: {sum(stats['total'] for stats in updated_stats.values()):,}\")\n",
    "print(f\"   Training: {updated_stats['train']['total']:,}\")\n",
    "print(f\"   Validation: {updated_stats['val']['total']:,}\")\n",
    "print(f\"   Test: {updated_stats['test']['total']:,}\")\n",
    "print(f\"   Classes: {len(updated_stats['train']['classes'])}\")\n",
    "print(f\"   Duplicates removed: {duplicates_removed}\")\n",
    "\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27542902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ COMBINING BEST OF BOTH APPROACHES\n",
      "============================================================\n",
      "‚úÖ Data leakage: FIXED (from fix_model_issues.ipynb)\n",
      "‚úÖ Architecture: Lightweight CNN (from inspect_dataset.ipynb)\n",
      "‚úÖ Clean splits: Using clean_split_path\n",
      "‚úÖ No duplicates: Already removed\n",
      "\n",
      "üìä Setting up data generators for clean data...\n",
      "Found 25537 images belonging to 23 classes.\n",
      "Found 7145 images belonging to 23 classes.\n",
      "Found 7145 images belonging to 23 classes.\n",
      "‚úÖ Clean data generators created:\n",
      "   Training: 25,537 images\n",
      "   Validation: 7,145 images\n",
      "   Test: 7,145 images\n",
      "   Classes: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Crop Disease model\\.venv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèóÔ∏è Lightweight CNN created for clean data:\n",
      "   Parameters: 134,103\n",
      "   Classes: 23\n",
      "‚úÖ Model compiled and ready for training\n",
      "‚úÖ Training callbacks configured\n",
      "\n",
      "üöÄ STARTING LIGHTWEIGHT CNN TRAINING ON CLEAN DATA\n",
      "============================================================\n",
      "Training setup:\n",
      "   Steps per epoch: 798\n",
      "   Validation steps: 223\n",
      "   Max epochs: 20\n",
      "   Early stopping: patience=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Crop Disease model\\.venv\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.4644 - loss: 1.8562\n",
      "Epoch 1: val_loss improved from inf to 1.72890, saving model to best_lightweight_clean_again_20250709_101912.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4320s\u001b[0m 5s/step - accuracy: 0.4646 - loss: 1.8556 - val_accuracy: 0.5785 - val_loss: 1.7289 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m  1/798\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m33:49\u001b[0m 3s/step - accuracy: 0.7188 - loss: 0.7427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Crop Disease model\\.venv\\lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_loss did not improve from 1.72890\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 103ms/step - accuracy: 0.7188 - loss: 0.7427 - val_accuracy: 0.5786 - val_loss: 1.7685 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7462 - loss: 0.7967\n",
      "Epoch 3: val_loss did not improve from 1.72890\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2310s\u001b[0m 3s/step - accuracy: 0.7462 - loss: 0.7967 - val_accuracy: 0.5161 - val_loss: 2.7720 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m  1/798\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m35:10\u001b[0m 3s/step - accuracy: 0.7812 - loss: 0.7936\n",
      "Epoch 4: val_loss did not improve from 1.72890\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 105ms/step - accuracy: 0.7812 - loss: 0.7936 - val_accuracy: 0.5929 - val_loss: 2.0445 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8169 - loss: 0.5626\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 5: val_loss did not improve from 1.72890\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2404s\u001b[0m 3s/step - accuracy: 0.8169 - loss: 0.5626 - val_accuracy: 0.5603 - val_loss: 1.7346 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m  1/798\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m35:10\u001b[0m 3s/step - accuracy: 0.8438 - loss: 0.3605\n",
      "Epoch 6: val_loss did not improve from 1.72890\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 107ms/step - accuracy: 0.8438 - loss: 0.3605 - val_accuracy: 0.5460 - val_loss: 1.8237 - learning_rate: 5.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8748 - loss: 0.3891\n",
      "Epoch 7: val_loss improved from 1.72890 to 0.59813, saving model to best_lightweight_clean_again_20250709_101912.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2382s\u001b[0m 3s/step - accuracy: 0.8748 - loss: 0.3891 - val_accuracy: 0.8295 - val_loss: 0.5981 - learning_rate: 5.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m  1/798\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m31:56\u001b[0m 2s/step - accuracy: 0.8750 - loss: 0.2839\n",
      "Epoch 8: val_loss did not improve from 0.59813\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 117ms/step - accuracy: 0.8750 - loss: 0.2839 - val_accuracy: 0.8205 - val_loss: 0.6422 - learning_rate: 5.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.8953 - loss: 0.3218\n",
      "Epoch 9: val_loss did not improve from 0.59813\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2523s\u001b[0m 3s/step - accuracy: 0.8953 - loss: 0.3218 - val_accuracy: 0.7241 - val_loss: 0.9862 - learning_rate: 5.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m  1/798\u001b[0m \u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m48:45\u001b[0m 4s/step - accuracy: 0.8750 - loss: 0.2250\n",
      "Epoch 10: val_loss did not improve from 0.59813\n",
      "\u001b[1m798/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 148ms/step - accuracy: 0.8750 - loss: 0.2250 - val_accuracy: 0.7309 - val_loss: 0.9560 - learning_rate: 5.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m577/798\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m13:39\u001b[0m 4s/step - accuracy: 0.9061 - loss: 0.2929"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LIGHTWEIGHT CNN TRAINING - USING CLEAN DATA FROM FIX_MODEL_ISSUES\n",
    "# =============================================================================\n",
    "\n",
    "def create_lightweight_cnn_for_clean_data(input_shape=(224, 224, 3), num_classes=None):\n",
    "    \"\"\"Create lightweight CNN using the successful architecture from inspect_dataset\"\"\"\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        # First block\n",
    "        tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "        # Second block\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "        # Third block\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(0.25),\n",
    "        \n",
    "        # Classifier\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"üöÄ COMBINING BEST OF BOTH APPROACHES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Data leakage: FIXED (from fix_model_issues.ipynb)\")\n",
    "print(\"‚úÖ Architecture: Lightweight CNN (from inspect_dataset.ipynb)\")\n",
    "print(\"‚úÖ Clean splits: Using clean_split_path\")\n",
    "print(\"‚úÖ No duplicates: Already removed\")\n",
    "\n",
    "# =============================================================================\n",
    "# SETUP DATA GENERATORS FOR CLEAN DATA\n",
    "# =============================================================================\n",
    "\n",
    "def setup_clean_data_generators(clean_split_path, batch_size=32, img_size=(224, 224)):\n",
    "    \"\"\"Setup data generators using the clean splits\"\"\"\n",
    "    \n",
    "    print(\"\\nüìä Setting up data generators for clean data...\")\n",
    "    \n",
    "    # Training generator - minimal augmentation since we already augmented\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.05\n",
    "    )\n",
    "    \n",
    "    # Val/test generators - only rescaling\n",
    "    val_test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(clean_split_path, 'train'),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    val_generator = val_test_datagen.flow_from_directory(\n",
    "        os.path.join(clean_split_path, 'val'),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    test_generator = val_test_datagen.flow_from_directory(\n",
    "        os.path.join(clean_split_path, 'test'),\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Clean data generators created:\")\n",
    "    print(f\"   Training: {train_generator.samples:,} images\")\n",
    "    print(f\"   Validation: {val_generator.samples:,} images\")\n",
    "    print(f\"   Test: {test_generator.samples:,} images\")\n",
    "    print(f\"   Classes: {train_generator.num_classes}\")\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "# Setup generators using the clean splits from fix_model_issues\n",
    "clean_train_gen, clean_val_gen, clean_test_gen = setup_clean_data_generators(clean_split_path)\n",
    "\n",
    "# =============================================================================\n",
    "# CREATE AND COMPILE LIGHTWEIGHT MODEL\n",
    "# =============================================================================\n",
    "\n",
    "# Create lightweight CNN\n",
    "num_classes = clean_train_gen.num_classes\n",
    "lightweight_model_clean = create_lightweight_cnn_for_clean_data(num_classes=num_classes)\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Lightweight CNN created for clean data:\")\n",
    "print(f\"   Parameters: {lightweight_model_clean.count_params():,}\")\n",
    "print(f\"   Classes: {num_classes}\")\n",
    "\n",
    "# Compile model\n",
    "lightweight_model_clean.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Model compiled and ready for training\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRAINING CALLBACKS\n",
    "# =============================================================================\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=4,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'best_lightweight_clean_again_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Training callbacks configured\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRAIN THE MODEL\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüöÄ STARTING LIGHTWEIGHT CNN TRAINING ON CLEAN DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate steps\n",
    "steps_per_epoch = clean_train_gen.samples // clean_train_gen.batch_size\n",
    "validation_steps = clean_val_gen.samples // clean_val_gen.batch_size\n",
    "\n",
    "print(f\"Training setup:\")\n",
    "print(f\"   Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"   Validation steps: {validation_steps}\")\n",
    "print(f\"   Max epochs: 20\")\n",
    "print(f\"   Early stopping: patience=8\")\n",
    "\n",
    "# Start training with timing\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "history = lightweight_model_clean.fit(\n",
    "    clean_train_gen,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=clean_val_gen,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Training completed in {training_time/60:.1f} minutes\")\n",
    "print(f\"‚úÖ Best model saved automatically\")\n",
    "\n",
    "# =============================================================================\n",
    "# EVALUATE ON TEST SET\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìä EVALUATING ON TEST SET\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Reset test generator\n",
    "clean_test_gen.reset()\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_accuracy = lightweight_model_clean.evaluate(clean_test_gen, verbose=1)\n",
    "\n",
    "print(f\"\\nüéØ FINAL RESULTS (NO DATA LEAKAGE):\")\n",
    "print(f\"   Test Loss: {test_loss:.4f}\")\n",
    "print(f\"   Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.1f}%)\")\n",
    "print(f\"   Training Time: {training_time/60:.1f} minutes\")\n",
    "print(f\"   Model Parameters: {lightweight_model_clean.count_params():,}\")\n",
    "\n",
    "# Get predictions for detailed analysis\n",
    "y_pred = lightweight_model_clean.predict(clean_test_gen, verbose=1)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = clean_test_gen.classes\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "balanced_acc = balanced_accuracy_score(y_true, y_pred_classes)\n",
    "\n",
    "print(f\"   Balanced Accuracy: {balanced_acc:.4f} ({balanced_acc*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# RESULTS COMPARISON\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\nüìà RESULTS COMPARISON:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"BEFORE (inspect_dataset.ipynb):\")\n",
    "print(\"   ‚ùå Data leakage present\")\n",
    "print(\"   üéØ Validation accuracy: 89.45% (inflated)\")\n",
    "print(\"   ‚ö†Ô∏è  Results not trustworthy\")\n",
    "\n",
    "print(f\"\\nAFTER (fix_model_issues.ipynb + lightweight CNN):\")\n",
    "print(f\"   ‚úÖ Data leakage: FIXED\")\n",
    "print(f\"   ‚úÖ Duplicates: REMOVED\")\n",
    "print(f\"   üéØ Test accuracy: {test_accuracy*100:.1f}% (legitimate)\")\n",
    "print(f\"   üéØ Balanced accuracy: {balanced_acc*100:.1f}% (robust)\")\n",
    "print(f\"   ‚úÖ Results: TRUSTWORTHY\")\n",
    "\n",
    "# Expected vs Actual\n",
    "expected_drop = 10  # 10-15% drop expected after fixing data leakage\n",
    "actual_accuracy = test_accuracy * 100\n",
    "print(f\"\\nüìä EXPECTATION vs REALITY:\")\n",
    "print(f\"   Expected after fix: 75-80% (89.45% - 10-15%)\")\n",
    "print(f\"   Actual result: {actual_accuracy:.1f}%\")\n",
    "\n",
    "if actual_accuracy >= 75:\n",
    "    print(f\"   ‚úÖ EXCELLENT - Results meet expectations!\")\n",
    "elif actual_accuracy >= 65:\n",
    "    print(f\"   üü° GOOD - Reasonable performance\")\n",
    "else:\n",
    "    print(f\"   üî¥ NEEDS IMPROVEMENT\")\n",
    "\n",
    "print(f\"\\nüéâ LEGITIMATE CROP DISEASE MODEL COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
